{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9a278a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "ass_paths = glob(\"../data/Subtitles/*.ass\")\n",
    "srt_paths = glob(\"../data/Subtitles/*.srt\")\n",
    "\n",
    "subtitles_paths = sorted(ass_paths + srt_paths)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbf345f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtitles_paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553a5165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "scripts = []\n",
    "episode_num = []\n",
    "\n",
    "for path in subtitles_paths:\n",
    "    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "        # Skip header lines if it's an .ass file\n",
    "        if path.endswith(\".ass\"):\n",
    "            lines = lines[27:]\n",
    "            rows = [\",\".join(line.split(\",\")[9:]) for line in lines]\n",
    "            rows = [line.replace(\"\\\\N\", \" \") for line in rows]\n",
    "            script = \" \".join(rows)\n",
    "\n",
    "        elif path.endswith(\".srt\"):\n",
    "            # Basic .srt parsing: skip subtitle numbers and timestamps\n",
    "            lines = [line.strip() for line in lines if line.strip()]\n",
    "            rows = [\n",
    "                line\n",
    "                for line in lines\n",
    "                if not re.match(r\"^\\d+$\", line)\n",
    "                and not re.match(r\"^\\d{2}:\\d{2}:\\d{2},\\d{3}\", line)\n",
    "            ]\n",
    "            script = \" \".join(rows)\n",
    "\n",
    "        # Try to extract episode number using regex\n",
    "        filename = path.split(\"/\")[-1]\n",
    "        match = re.search(r\"\\d+\", filename)\n",
    "        if match:\n",
    "            episode = int(match.group())\n",
    "            scripts.append(script)\n",
    "            episode_num.append(episode)\n",
    "        else:\n",
    "            print(f\"⚠️ Couldn't find episode number in filename: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3697c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c006410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_dict({\"episode\": episode_num, \"script\": scripts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca9b3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aafa956",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a09428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295b98ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_trf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a863549",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Mark went to Germany\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d718ff6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5d65ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cebae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "\n",
    "\n",
    "def get_ners(script):\n",
    "    script_sentences = sent_tokenize(script)\n",
    "\n",
    "    ner_output = []\n",
    "\n",
    "    for sentence in script_sentences:\n",
    "        doc = nlp(sentence)\n",
    "        ners = set()\n",
    "        for ent in docs.ents:\n",
    "            if ent.label_ == \"PERSON\":\n",
    "                full_name = ent.text\n",
    "                first_name = full_name.split(\" \")[0]\n",
    "                ners.add(first_name)\n",
    "        ner_output.append(list(ners))\n",
    "    return ner_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b32465",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ners\"] = df[\"script\"].apply(get_ners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bf9d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 10\n",
    "entity_relationship = []\n",
    "\n",
    "for row in df[\"ners\"]:\n",
    "    previous_entitties_in_window = []\n",
    "\n",
    "    for sentence in row:\n",
    "        previous_entitties_in_window.append(sentence)\n",
    "        previous_entities_in_window = previous_entities_in_window[-10:]\n",
    "\n",
    "        previous_entities_flattened = sum(previous_entities_in_window, [])\n",
    "\n",
    "        for entity in sentence:\n",
    "            for entity_in_window in previous_entities_flattened:\n",
    "                if entity != entity_in_window:\n",
    "                    entity_rel = sorted([entity, entity_in_window])\n",
    "                    entity_relationship.append(entity_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9661bc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship_df = pd.DataFrame({\"value\": entity_relationship})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eb9ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship_df[\"source\"] = relationship_df[\"value\"].apply(lambda x: x[0])\n",
    "relationship_df[\"target\"] = relationship_df[\"value\"].apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63afa730",
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship_df = relationship_df.groupby([\"source\", \"target\"]).count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5650fd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship_df = relationship_df.sort_values(\"value\", ascending=False)\n",
    "relationship_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed4aa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "relationship_df = relationship_df.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af70d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = nx.from_pandas_edgelist(\n",
    "    relationship_df,\n",
    "    source=\"source\",\n",
    "    target=\"target\",\n",
    "    edge_attr=\"value\",\n",
    "    create_using=nx.Graph(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc17e5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "pos = nx.kamada_kawai_layout(G)\n",
    "nx.draw(G, with_labels=True, node_color=\"skyblue\", edge_cmap=plt.cm.Blues, pos=pos)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80761342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "\n",
    "net = Network(\n",
    "    notebook=True, width=\"1000px\", height=\"700px\", bgcolor=\"#222222\", font_color=\"white\"\n",
    ")\n",
    "\n",
    "node_degree = dict(G.degree)\n",
    "\n",
    "nx.set_node_attributes(G, node_degree, \"size\")\n",
    "\n",
    "net.from_nx(G)\n",
    "net.show(\"naruto.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
